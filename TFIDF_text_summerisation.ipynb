{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1yc_T73jxc18f8ilSqI1yr_jsNsSVlWGn",
      "authorship_tag": "ABX9TyNCAqWLxsEhW30DYv2G1o9g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jude-Morgan/Machine-Learning-projects/blob/main/TFIDF_text_summerisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgfPkQAE2W1A"
      },
      "outputs": [],
      "source": [
        "#Import the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import seaborn as sns\n",
        "import textwrap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import natural language toolkit\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stop_words')\n",
        "nltk.download('punkt')\n",
        "from nltk import sent_tokenize, word_tokenize, PorterStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "6u6E3iNAKXmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2905654-aa66-43f3-ca94-5a22fbc2ba5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Error loading stop_words: Package 'stop_words' not found\n",
            "[nltk_data]     in index\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu2O0geIIvoR",
        "outputId": "776ce6be-a398-4851-8c20-4dca05d1059e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYQOwdqcvq0b",
        "outputId": "37350074-121d-42ea-f2cd-71cd9d4ef9b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.10/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "DzKlRzGtAa5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "g2ldVGtGAcPw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c35ee187-9ddd-4510-a472-3895dd1a7bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Airplane_Seat_Article.csv\", encoding = \"ISO-8859-1\")\n",
        "#Print dataframe\n",
        "data"
      ],
      "metadata": {
        "id": "cpZpByaE9O9m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "157e1d98-5283-474c-f9e9-fe3f8c3b964b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   article_id                                            article  \\\n",
              "0           1  Ever noticed how plane seats appear to be gett...   \n",
              "\n",
              "                                          highlights  \n",
              "0  Experts question if  packed out planes are put...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ed63d97-0c91-4c8d-8ae0-6443117f30fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_id</th>\n",
              "      <th>article</th>\n",
              "      <th>highlights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Ever noticed how plane seats appear to be gett...</td>\n",
              "      <td>Experts question if  packed out planes are put...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ed63d97-0c91-4c8d-8ae0-6443117f30fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2ed63d97-0c91-4c8d-8ae0-6443117f30fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2ed63d97-0c91-4c8d-8ae0-6443117f30fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.columns)"
      ],
      "metadata": {
        "id": "ord3k4249aJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27212650-15ab-4c3f-a509-eb82b082c45a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['article_id', 'article', 'highlights'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import contractions\n",
        "\n",
        "def clean_text(text):\n",
        "#Cleans text by removing noise and formatting\n",
        "  #Remove URLs\n",
        "  text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', ' ', text, flags=re.MULTILINE)\n",
        "  #Remove HTML tags\n",
        "  text = re.sub(r'\\<a href', ' ', text)\n",
        "  #Remove ampersands\n",
        "  text = re.sub(r'&amp;', ' ', text)\n",
        "  #Remove special characters\n",
        "  text = re.sub(r'[_\\-;%()|+&=*%:#$@\\[\\]/]', ' ', text)\n",
        "  #Remove line breaks\n",
        "  text = re.sub(r'<br />', ' ', text)\n",
        "  #Remove single quotes\n",
        "  text = re.sub(r'\\'', ' ', text)\n",
        "  #Remove newlines\n",
        "  text = re.sub(r'\\n', ' ', text)\n",
        "  #Remove est\n",
        "  text = re.sub(' est ',' ', text)\n",
        "  #Replace question marks and exclamation points with periods\n",
        "  text = re.sub(r'[?!]', '.', text)\n",
        "  return text\n",
        "\n",
        "#Expands contractions in text\n",
        "def expand_contractions(text):\n",
        "  text = text.split()\n",
        "  final = []\n",
        "  for word in text:\n",
        "    try:\n",
        "      final.append(contractions.fix(word) + \" \")\n",
        "    except:\n",
        "      final.append(word + \" \")\n",
        "  return \"\".join(final)\n",
        "\n",
        "#Removes sentences from a list of texts that are less than 5 words long\n",
        "def remove_short_sentences(texts):\n",
        "  final = []\n",
        "  for text in texts:\n",
        "    sents = []\n",
        "    sentences = text.split(\".\")\n",
        "    for sentence in sentences:\n",
        "      if len(sentence.split()) >= 5:\n",
        "        sents.append(sentence + \".\")\n",
        "    final.append(\"\".join(sents))\n",
        "  return final\n",
        "\n",
        "#Removes the CNN and est tags from a list of texts\n",
        "def remove_tag(texts):\n",
        "  final = []\n",
        "  for text in texts:\n",
        "    cnn = text.find(\"cnn\")\n",
        "    if cnn != -1 and cnn < len(text) // 10:\n",
        "      text = text[cnn + 3:]\n",
        "    found = False\n",
        "    for i in range(2):\n",
        "      est = text.find(\" est,\")\n",
        "      if est < len(text) // 5 and est != -1:\n",
        "        text = text[est + 5:]\n",
        "        found = True\n",
        "    fs = text.find(\".\")\n",
        "    if fs < 20 and fs != -1 and found:\n",
        "      text = text[fs:]\n",
        "    final.append(text)\n",
        "  return final\n",
        "\n",
        "#Preprocesses text by cleaning it, expanding contractions, removing short sentences, and removing the CNN and est tags\n",
        "def preprocess_text(text):\n",
        "  text = clean_text(text)\n",
        "  text = expand_contractions(text)\n",
        "  text = remove_short_sentences([text])[0]\n",
        "  text = remove_tag([text])[0]\n",
        "  return text"
      ],
      "metadata": {
        "id": "hNWDDTFo8nYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = data.iloc[:, 1]\n",
        "new_texts = []\n",
        "for text in texts:\n",
        "  new_texts.append(expand_contractions(clean_text(text)).lower())\n",
        "final_cleaned = remove_tag(remove_short_sentences(new_texts))"
      ],
      "metadata": {
        "id": "3JQQcUiYhUkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summaries = data.iloc[:, 2]\n",
        "new_summaries = []\n",
        "for summary in summaries:\n",
        "  new_summaries.append(expand_contractions(clean_text(summary)).lower())"
      ],
      "metadata": {
        "id": "JEzC32q553K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create new dataframe with preprocessed texts and summaries\n",
        "new_data = pd.DataFrame()\n",
        "new_data[\"Texts\"] = final_cleaned\n",
        "new_data[\"Summaries\"] = new_summaries"
      ],
      "metadata": {
        "id": "HlxLMLiJ569P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.to_csv(\"Cleaned.csv\")\n",
        "new_data"
      ],
      "metadata": {
        "id": "IEUIwy-q58cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "d4e6e8bd-3cc1-4cdc-8ee7-f715ace93d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Texts  \\\n",
              "0  ever noticed how plane seats appear to be gett...   \n",
              "\n",
              "                                           Summaries  \n",
              "0  experts question if packed out planes are putt...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cbad470a-1728-495e-9e0b-fcb7b9f194b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Texts</th>\n",
              "      <th>Summaries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ever noticed how plane seats appear to be gett...</td>\n",
              "      <td>experts question if packed out planes are putt...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbad470a-1728-495e-9e0b-fcb7b9f194b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cbad470a-1728-495e-9e0b-fcb7b9f194b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cbad470a-1728-495e-9e0b-fcb7b9f194b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_data.columns)"
      ],
      "metadata": {
        "id": "2HJYBxvJRzxc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9fc1d09-ef99-4036-85d9-eb4e560636c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Texts', 'Summaries'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.columns = new_data.columns.astype(str)\n",
        "print(new_data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V9qVvylAX1n",
        "outputId": "d88d1ce9-18d6-4b40-e352-8a0a0cf459fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Texts', 'Summaries'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Returns a set of all the words in the given texts\n",
        "def words(texts: list) -> set:\n",
        "    import re\n",
        "    all_words = set()\n",
        "    for text in texts:\n",
        "        text = re.sub(r\"[.,]\", \" \", text)\n",
        "        all_words |= set(text.split())\n",
        "    return all_words\n",
        "\n",
        "final_cleaned = [\"This is a sentence. This is another sentence.\"]\n",
        "swords = words(final_cleaned)"
      ],
      "metadata": {
        "id": "EykwnkpNEpVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Returns a dictionary of term frequencies for the given sentences\n",
        "def create_frequency_matrix(sentences: list) -> dict:\n",
        "    frequency_matrix = {}\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    stemmer = PorterStemmer()\n",
        "\n",
        "    for sentence in sentences:\n",
        "        frequency_table = {}\n",
        "        words = word_tokenize(sentence)\n",
        "        for word in words:\n",
        "            word = word.lower()\n",
        "            word = stemmer.stem(word)\n",
        "            if word in stop_words:\n",
        "                continue\n",
        "\n",
        "            if word in frequency_table:\n",
        "                frequency_table[word] += 1\n",
        "            else:\n",
        "                frequency_table[word] = 1\n",
        "\n",
        "        frequency_matrix[sentence[:15]] = frequency_table\n",
        "\n",
        "    return frequency_matrix"
      ],
      "metadata": {
        "id": "mDDAoFzcFgd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Returns a dictionary of term frequencies for the given sentences\n",
        "def create_tf_matrix(frequency_matrix: dict) -> dict:\n",
        "    tf_matrix = {}\n",
        "\n",
        "    for sentence, frequency_table in frequency_matrix.items():\n",
        "        tf_table = {}\n",
        "\n",
        "        count_words_in_sentence = len(frequency_table)\n",
        "        for word, count in frequency_table.items():\n",
        "            tf_table[word] = count / count_words_in_sentence\n",
        "\n",
        "        tf_matrix[sentence] = tf_table\n",
        "\n",
        "    return tf_matrix"
      ],
      "metadata": {
        "id": "0fZqGRArPgh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Returns a dictionary of the number of documents each word appears in\n",
        "def create_documents_per_words(frequency_matrix: dict) -> dict:\n",
        "    word_per_document_table = {}\n",
        "\n",
        "    for sentence, frequency_table in frequency_matrix.items():\n",
        "        for word, count in frequency_table.items():\n",
        "            if word in word_per_document_table:\n",
        "                word_per_document_table[word] += 1\n",
        "            else:\n",
        "                word_per_document_table[word] = 1\n",
        "\n",
        "    return word_per_document_table"
      ],
      "metadata": {
        "id": "xANjbNc0Q8WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Returns a dictionary of inverse document frequencies for the given sentences\n",
        "def create_idf_matrix(frequency_matrix: dict, documents_per_word_table: dict, total_documents: int) -> dict:\n",
        "    idf_matrix = {}\n",
        "\n",
        "    for sentence, frequency_table in frequency_matrix.items():\n",
        "        idf_table = {}\n",
        "\n",
        "        for word in frequency_table.keys():\n",
        "            idf_table[word] = math.log10(total_documents / float(documents_per_word_table[word]))\n",
        "\n",
        "        idf_matrix[sentence] = idf_table\n",
        "\n",
        "    return idf_matrix"
      ],
      "metadata": {
        "id": "ACwdSVllRjar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Returns a dictionary of term frequency-inverse document frequency for the given sentences\n",
        "def create_tf_idf_matrix(tf_matrix: dict, idf_matrix: dict) -> dict:\n",
        "    tf_idf_matrix = {}\n",
        "\n",
        "    for (sentence1, tf_table1), (sentence2, tf_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
        "        tf_idf_table = {}\n",
        "\n",
        "        for (word1, value1), (word2, value2) in zip(tf_table1.items(), tf_table2.items()):\n",
        "            tf_idf_table[word1] = float(value1 * value2)\n",
        "\n",
        "        tf_idf_matrix[sentence1] = tf_idf_table\n",
        "\n",
        "    return tf_idf_matrix"
      ],
      "metadata": {
        "id": "60qMGsaYRr72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#score a sentence by its word's TF Basic algorithm: adding the TF frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
        "\n",
        "def score_sentences(tf_idf_matrix: dict) -> dict:\n",
        "    sentence_scores = {}\n",
        "\n",
        "    for sentence, tf_idf_table in tf_idf_matrix.items():\n",
        "        total_score_per_sentence = 0.0\n",
        "\n",
        "        count_words_in_sentence = len(tf_idf_table)\n",
        "        for word, score in tf_idf_table.items():\n",
        "            total_score_per_sentence += score\n",
        "\n",
        "        sentence_scores[sentence] = total_score_per_sentence / count_words_in_sentence\n",
        "\n",
        "    return sentence_scores"
      ],
      "metadata": {
        "id": "5Dif4r_LRwKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Returns the average score of sentences from the sentence scores dictionary\n",
        "def find_average_score(sentence_scores: dict) -> float:\n",
        "    sum_of_scores = 0.0\n",
        "    for sentence, score in sentence_scores.items():\n",
        "        sum_of_scores += score\n",
        "\n",
        "    average_score = sum_of_scores / len(sentence_scores)\n",
        "\n",
        "    return average_score"
      ],
      "metadata": {
        "id": "5k8k3yb_R0Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Returns a summary of the given sentences based on their sentence scores and the given threshold\n",
        "def generate_summary_TFIDF(sentences: list, sentence_scores: dict, threshold: float) -> str:\n",
        "    sentence_count = 0\n",
        "    summary = \"\"\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if sentence[:15] in sentence_scores and sentence_scores[sentence[:15]] >= threshold:\n",
        "            summary += \" \" + sentence\n",
        "            sentence_count += 1\n",
        "\n",
        "    return summary"
      ],
      "metadata": {
        "id": "zkiF1fHqR3ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "#Sentence Tokenize\n",
        "sentences = sent_tokenize(text)\n",
        "total_documents = len(sentences)\n",
        "#print(sentences)\n",
        "\n",
        "#Create the Frequency matrix of the words in each sentence.\n",
        "freq_matrix = create_frequency_matrix(sentences)\n",
        "#print(freq_matrix)\n",
        "\n",
        "#Calculate TermFrequency and generate a matrix\n",
        "tf_matrix = create_tf_matrix(freq_matrix)\n",
        "#print(tf_matrix)\n",
        "\n",
        "#Creating table for documents per words\n",
        "count_doc_per_words = create_documents_per_words(freq_matrix)\n",
        "#print(count_doc_per_words)\n",
        "\n",
        "#Calculate IDF and generate a matrix\n",
        "idf_matrix = create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
        "#print(idf_matrix)\n",
        "\n",
        "#Calculate TF-IDF and generate a matrix\n",
        "tf_idf_matrix = create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
        "#print(tf_idf_matrix)\n",
        "\n",
        "#Important Algorithm: score the sentences\n",
        "sentence_scores = score_sentences(tf_idf_matrix)\n",
        "#print(sentence_scores)\n",
        "\n",
        "#Find the threshold\n",
        "threshold = find_average_score(sentence_scores)\n",
        "#print(threshold)\n",
        "\n",
        "#Generate summary\n",
        "summary = generate_summary_TFIDF(sentences, sentence_scores, 1.3 * threshold)\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "CtqJYt-LSJfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "939e27d6-1cb6-4211-bc67-570e4cd2693b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Ever noticed how plane seats appear to be getting smaller and smaller? The distance between two seats from one point on a seat to the same point on the seat behind it is known as the pitch.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "#Generate summary\n",
        "generated_summary = generate_summary_TFIDF(sentences, sentence_scores, 1.3 * threshold)\n",
        "\n",
        "#Tokenize the generated summary and reference summaries\n",
        "generated_summary_tokens = word_tokenize(generated_summary)\n",
        "reference_summaries_tokens = [word_tokenize(summary) for summary in new_data[\"Summaries\"]]\n",
        "\n",
        "#Calculate BLEU score\n",
        "bleu_score = sentence_bleu(reference_summaries_tokens, generated_summary_tokens, smoothing_function=SmoothingFunction().method1)\n",
        "\n",
        "#Print BLEU score\n",
        "print(\"BLEU Score:\", bleu_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTqs9PXW_eYy",
        "outputId": "e7f67b8c-b2e0-43db-cbf8-aaa27667e35b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.006243702571093031\n"
          ]
        }
      ]
    }
  ]
}